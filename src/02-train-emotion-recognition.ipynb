{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from src.config import opt\n",
    "from src.stylegan_clip import Model\n",
    "from src.emotion_recognition.model import EmotionModel\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def __init_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def calculate_f1(preds, labels):\n",
    "    return f1_score(labels, preds, average='micro')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class EmotionDataloader:\n",
    "    def __init__(self, is_eval=False, use_mtcnn=True,):\n",
    "        self.is_eval = is_eval\n",
    "        self.use_mtcnn = use_mtcnn\n",
    "        self.er_transformations = T.Compose([\n",
    "            T.GaussianBlur(kernel_size=(3, 3), sigma=1),\n",
    "            T.GaussianBlur(kernel_size=(5, 9), sigma=2),\n",
    "            T.Normalize(mean=opt.mean, std=opt.std),\n",
    "        ])\n",
    "\n",
    "        self.er_transformations_train = T.Compose([\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            T.RandomChoice([\n",
    "                T.RandomRotation(degrees=(-45, 45)),\n",
    "                T.RandomRotation(degrees=(0, 0)),\n",
    "            ], p=[0.25, 0.75]),\n",
    "        ])\n",
    "\n",
    "        self.mtcnn = MTCNN(\n",
    "            image_size=256, margin=0, min_face_size=20,\n",
    "            thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "            device=opt.device\n",
    "        )\n",
    "        self.model = Model(path_to_checkpoint=join(opt.path_to_stylegan_checkpoints, 'neutral'), device=opt.device)\n",
    "\n",
    "    def prepare_img(self, data):\n",
    "        data = data.add(1).div(2).squeeze()\n",
    "        if not self.is_eval:\n",
    "            data = self.er_transformations_train(data).to(opt.device)\n",
    "\n",
    "        if self.use_mtcnn:\n",
    "            data = self.mtcnn(\n",
    "                data.permute(1, 2, 0).mul(255).detach().cpu().numpy(),\n",
    "                return_prob=False,\n",
    "            )\n",
    "            if data is None:\n",
    "                return None\n",
    "            data = data.add(1).div(2).squeeze()\n",
    "        return self.er_transformations(data).to(opt.device)\n",
    "\n",
    "    def get_batch(self, batch_size):\n",
    "        targets_b, emotions_b = [], []\n",
    "        for b in range(batch_size):\n",
    "            data = None\n",
    "            emo = None\n",
    "            while data is None:\n",
    "                noise = torch.randn(1, 512, device=opt.device)\n",
    "                emo = random.choice(opt.emotion_list)\n",
    "                self.model.load_checkpoint(join(opt.path_to_stylegan_checkpoints, emo))\n",
    "                data = self.model.inference(1, noise)[1:]\n",
    "                data = self.prepare_img(data[1])\n",
    "            data = data.unsqueeze(0)\n",
    "\n",
    "            targets_b.append(data)\n",
    "            target_emotion = torch.zeros([1, 7]).to(opt.device)\n",
    "            target_emotion[:, opt.emotion_list.index(emo)] = 1\n",
    "            emotions_b.append(target_emotion)\n",
    "        return torch.cat(targets_b), torch.cat(emotions_b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "dataloader = EmotionDataloader(is_eval=False, use_mtcnn=False)\n",
    "noise = torch.randn(1, 512, device=opt.device)\n",
    "model = Model(path_to_checkpoint=join(opt.path_to_stylegan_checkpoints, 'angry'), device=opt.device)\n",
    "data = model.inference(1, noise)[1:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "x = data[1].squeeze(0).add(1).div(2)\n",
    "transform = T.ToPILImage()\n",
    "img = transform(x)\n",
    "img.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def main():\n",
    "    dataloader = EmotionDataloader(is_eval=False, use_mtcnn=False)\n",
    "\n",
    "    emotion_model = EmotionModel().train().requires_grad_(True).to(opt.device)\n",
    "    emotion_model.freeze_middle_layers()\n",
    "\n",
    "    init_step = 0\n",
    "    if opt.path_to_er_weights_last3.exists():\n",
    "        last_state = torch.load(opt.path_to_er_weights_last3)\n",
    "        emotion_model.load_state_dict(last_state['state_dict'])\n",
    "        init_step = last_state['last_step'] + 1\n",
    "        print(f'weight were loaded {opt.path_to_er_weights_last3}')\n",
    "\n",
    "    emotion_model.unfreeze_all_layers()\n",
    "    optimizer = Adam(emotion_model.parameters(), lr=opt.lr_er)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=100, factor=0.75, verbose=True)\n",
    "\n",
    "    loss_history = []\n",
    "    f1_history = []\n",
    "    best_avg_f1 = 0\n",
    "    for step in tqdm(itertools.count(init_step), initial=init_step, desc='infinity training loop'):\n",
    "        optimizer.zero_grad()\n",
    "        target, target_emotions = dataloader.get_batch(opt.batch_size_er)\n",
    "        predicted_emotions = emotion_model(target)\n",
    "\n",
    "        val_target, val_target_emotions = dataloader.get_batch(opt.batch_size_er)\n",
    "        val_predicted_emotions = emotion_model(val_target)\n",
    "\n",
    "        loss = F.cross_entropy(predicted_emotions, target_emotions)\n",
    "        val_loss = F.cross_entropy(val_predicted_emotions, val_target_emotions)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step(loss)\n",
    "\n",
    "        val_f1_score_res = calculate_f1(\n",
    "            np.argmax(F.softmax(val_predicted_emotions, dim=1).detach().cpu().numpy().tolist(), axis=1),\n",
    "            np.argmax(val_target_emotions.cpu().numpy().tolist(), axis=1),\n",
    "        )\n",
    "\n",
    "        loss_history.append(val_loss.item())\n",
    "        f1_history.append(val_f1_score_res)\n",
    "\n",
    "        if ((step % opt.n_write_log) == 0) and opt.enable_log_flag:\n",
    "            grid = make_grid(target, nrow=opt.batch_size_er, padding=0, normalize=True,)\n",
    "            writer.add_image('er-img/target', grid, step)\n",
    "\n",
    "            avg_f1 = np.mean(f1_history)\n",
    "\n",
    "            writer.add_scalar('er-lr/learning_rate', optimizer.param_groups[0]['lr'], step)\n",
    "            writer.add_scalar('er-loss/cross-entropy-loss', val_loss.item(), step)\n",
    "            writer.add_scalar('er-metric/f1-micro-metric', val_f1_score_res, step)\n",
    "            writer.add_scalar('er-loss/avg-cross-entropy-loss', np.mean(loss_history), step)\n",
    "            writer.add_scalar('er-metric/avg-f1-micro-metric', avg_f1, step)\n",
    "            loss_history = []\n",
    "            f1_history = []\n",
    "\n",
    "            if best_avg_f1 < avg_f1:\n",
    "                best_avg_f1 = avg_f1\n",
    "                last_state = {\n",
    "                    'last_step': step,\n",
    "                    'state_dict': emotion_model.state_dict(),\n",
    "                }\n",
    "                torch.save(last_state, opt.path_to_er_weights_last3)\n",
    "\n",
    "                if best_avg_f1 >= 1.0:\n",
    "                    return"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    __init_seeds(opt.seed)\n",
    "\n",
    "    writer = SummaryWriter(log_dir=opt.path_to_er_tf_logs3)\n",
    "    main()\n",
    "    writer.close()\n",
    "\n",
    "    print('Training is finished!')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
